data_preparation:
  train_test_ratio: 0.7
  train_val_ratio: 0.9
  random_state: 42

linear_regression:
  model_name: 'LinearRegression'

decision_tree:
  DecisionTree:
    max_depth: [ 2, 4, 6, 7, 8, 9, 10, 12 ]
    splitter: [ 'best', 'random' ]
    min_samples_split: [ 2, 3, 4 ]
    min_samples_leaf: [ 1, 2, 3, 4 ]
  RandomForest:
    n_estimators: [1, 2, 5, 10, 15]
    max_depth: [ 2, 4, 6, 7, 8, 9, 10, 12 ]
    min_samples_split: [ 2, 3, 4, 6, 7 ]
    min_samples_leaf: [ 1, 2, 3, 4 ]
    n_jobs: [-1]
  ExtraTree:
    n_estimators: [1, 2, 5, 10, 15]
    max_depth: [ 2, 4, 6, 7, 8, 9, 10, 12 ]
    min_samples_split: [ 2, 3, 4, 10, 15 ]
    min_samples_leaf: [ 1, 2, 3, 4, 18, 48 ]
    n_jobs: [-1]

xg_boost:
  n_estimators: [15, 50, 100]
  max_depth: [3, 4, 5, 9, 15, 18]
  gamma: [1, 3, 5, 7, 9]
  min_child_weight: [1, 3, 5, 7, 9]
  verbosity: [0]

cat_boost:
  n_estimators: [50, 80]
  max_depth: [ 3, 4, 5, 9, 12]
  silent: [True]

NN:
  neurons_cnt: [100, 150 ]
  hidden_layers: [3, 6]
  batch_size: [64, 96]
  learning_rate: [0.05, 0.09]
