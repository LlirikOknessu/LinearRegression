data_preparation:
  train_test_ratio: 0.8
  train_val_ratio: 0.875
  random_state: 42
linear_regression:
  model_name: 'LinearRegression'
decision_tree:
  DecisionTree:
    max_depth: [  7, 10, 12, 15]
    splitter: [ 'best', 'random' ]
    min_samples_split: [ 2, 3, 4 ]
    min_samples_leaf: [ 1, 2, 3, 4 ]
  RandomForest:
    n_estimators: [1, 2, 5, 10, 15]
    max_depth: [ 7, 10, 12, 15]
    min_samples_split: [ 2, 3, 4, 6, 7 ]
    min_samples_leaf: [ 1, 2, 3, 4 ]
  ExtraTree:
    n_estimators: [1, 2, 5, 10, 15]
    max_depth: [  7, 10, 12, 15]
    min_samples_split: [ 2, 3, 4, 10, 15 ]
    min_samples_leaf: [ 1, 2, 3, 4, 10, 15 ]
boosting:
  XGBoostRegressor:
    booster: ['gbtree', 'dblinear']
    learning_rate: [3e-4, 3e-3, 0.01, 0.1, 0.3]
    max_depth: [4,6,8,10]
  CatBoostRegressor:
    iterations: [10,100]
    learning_rate: [3e-4, 3e-3, 0.01, 0.1, 0.3]
    depth: [4,6,8,10]
NeuralNetwork:
  n_of_neurons: [ 32, 64, 128]
  batch_size: [ 32, 64, 128]
  buffer_size: 128
  learning_rate: [ 0.01, 0.1, 0.5]
  epochs: 25
NeuralNetwork_full:
  n_of_neurons: 64
  batch_size: 64
  learning_rate: 0.01
  epochs: 100
  buffer_size: 128