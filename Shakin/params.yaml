data_preparation:
  train_test_ratio: 0.8
  train_val_ratio: 0.9
  random_state: 42
linear_regression:
  model_name: 'LinearRegression'
decision_tree:
  DecisionTree:
    max_depth: [ 2, 4, 6]
    splitter: [ 'best', 'random' ]
    min_samples_split: [ 2, 3, 4]
    min_samples_leaf: [ 1, 2, 3, 4]
  RandomForest:
    n_estimators: [1, 2, 5, 10]
    max_depth: [ 2, 4, 6, 8]
    min_samples_split: [ 2, 3, 4, 6, 8]
    min_samples_leaf: [ 1, 2, 3, 4 ]
  ExtraTree:
    n_estimators: [1, 2, 5, 10]
    max_depth: [ 2, 4, 6, 8, 10]
    min_samples_split: [ 2, 3, 4, 10]
    min_samples_leaf: [ 1, 2, 3, 4, 10]
XG_boosting:
  n_estimators: [5, 10, 20]
  max_depth: [ 3, 4, 5 ]
  gamma: [ 1, 2, 3 ]
  learning_rate: [ 0.01, 0.1, 0.5, 1 ]
  min_child_weight: [1, 3, 5 ]
CatBoosting:
  n_estimators: [50, 100, 150, 200]
  max_depth: [2, 3, 4, default = 6]
  learning_rate: [ 0.05, 0.1, default = 0.5 ]
NN:
  batch_size: [256]
  n_of_neurons: [8, 16, 32]
  buffer_size: 512
  learning_rate: [0.001]
  epochs: 100
NN_full:
  n_of_neurons: 64
  batch_size: 256
  learning_rate: 0.01
  epochs: 10
  buffer_size: 512

