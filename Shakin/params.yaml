data_preparation:
  train_test_ratio: 0.8
  train_val_ratio: 0.9
  random_state: 42
linear_regression:
  model_name: 'LinearRegression'
decision_tree:
  DecisionTree:
    max_depth: [ 2, 4, 6]
    splitter: [ 'best', 'random' ]
    min_samples_split: [ 2, 3, 4]
    min_samples_leaf: [ 1, 2, 3, 4]
  RandomForest:
    n_estimators: [1, 2, 5, 10]
    max_depth: [ 2, 4, 6, 8]
    min_samples_split: [ 2, 3, 4, 6, 8]
    min_samples_leaf: [ 1, 2, 3, 4 ]
  ExtraTree:
    n_estimators: [1, 2, 5, 10]
    max_depth: [ 2, 4, 6, 8, 10]
    min_samples_split: [ 2, 3, 4, 10]
    min_samples_leaf: [ 1, 2, 3, 4, 10]
XG_boosting:
  n_estimators: [5, 10, 20]
  max_depth: [ 3, 4, 5 ]
  gamma: [ 1, 2, 3 ]
  learning_rate: [ 0.01, 0.1, 0.5, 1 ]
  min_child_weight: [1, 3, 5 ]
CatBoosting:
  n_estimators: [50, 100, 150, 200]
#  max_depth: [2, 3, 4]
#  learning_rate: [ 0.05, 0.1 ]

