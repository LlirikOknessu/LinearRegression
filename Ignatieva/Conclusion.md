# Conclusion

## Выводы по работе с линейной регрессией

### Цель работы и задание

Создать модель линейной регрессии для предсказания posttest оценки, 
на основе предоставленных данных.
Датасет содержит следующую информацию об ученике: название, местоположение,
тип школы, тип классной комнаты, метод преподавания, количество учащихся в классе,
уникальный идентификатор, пол, право на бесплатный/ субсидируемый обед,
оценка предварительного тестирования, итоговая оценка.

## Выводы по каждому этапу

### Анализ данных (analyse.ipynb)

В ходе изучения и анализа предоставленных данных нужно было найти
такие характеристики, которые оказывают влияние на итоговую оценку за тест.
Анализ с помощью инструментов pandas, matplotlib и seaborn показал следующее:

 - данные оценки предварительного тестирования и послетестовой оценки
имеют довольно явную корреляцию;
 - оценки учащихся городских школ ниже, чем сельских и пригородных
и при этом учащиеся пригородных школ в основном показывают лучшие результаты;
 - учащиеся из частных школ показывают лучшие результаты по сравнению
с учащимися общеобразовательных школ;
 - ученики с экспериментальным видом обучения показывают имеют оценку выше,
однако это не так значительно;
 - у тех учащихся, которым не предоставляется бесплатный обед, оценка за тест,
как правило, выше.

Данные выводы помогли выбрать нужные характеристики для обучения модели.

### Подготовка данных (data_perparation.ry)

В ходе подготовки данных были созданы выборки: тестовая, тренировочная,
валидационная и полная. При этом ненужные данные были удалены, а остальные -
категоризированы.

### Обучение модели
 
Обучение данной модели происходило в три этапа:

- обучение на тренировочной выборке (linear_regression.py);
- проверка обученной модели на валидационной выборке
(linear_regression_val.py);
- прогон полной выборки и выкат модели в продакш
(linear_regression_full.py).

В идеале следовало бы прогнать модель еще через тестовую выборку, но
точность модели получилась довольно высокой, поэтому считаю это
не столь критичным.

В качестве baseline было использовано нормальное распределение, так как
оно было сочтено наиболее подходящим для уточнения предсказываний на
основе исходного датасета.

В качестве линейных моделей выбраны классические линейные регрессоры:
Ridge и LinearRegression. Опытным путем было выяснено, что, по 
крайней мере в данном случае, выбор регрессора не оказывает сильного
влияния на результат обучения.

При запуске выше упомянутых программ можно увидеть рассчитанные
среднеквадратичные ошибки baseline и модели. Заметим, что ошибка
становится в разы меньше, что говорит о том, что модель все-таки
обучается.
