data_preparation:
  train_test_ratio: 0.7
  train_val_ratio: 0.9
  random_state: 42
linear_regression:
  model_name: 'LinearRegression'
decision_tree:
  DecisionTree:
    max_depth: [ 2, 4, 6, 7 ]
    splitter: [ 'best', 'random' ]
    min_samples_split: [ 2, 3, 4 ]
    min_samples_leaf: [ 1, 2, 3, 4 ]
  RandomForest:
    n_estimators: [1, 2, 5, 10, 15]
    max_depth: [ 2, 4, 6, 7 ]
    min_samples_split: [ 2, 3, 4, 6, 7 ]
    min_samples_leaf: [ 1, 2, 3, 4 ]
  ExtraTree:
    n_estimators: [1, 2, 5, 10, 15]
    max_depth: [ 2, 4, 6, 7 ]
    min_samples_split: [ 2, 3, 4, 10, 15 ]
    min_samples_leaf: [ 1, 2, 3, 4, 18, 48 ]
xgboost:
  model_name: 'XGBoost'
  n_estimators: [ 1, 2, 5, 10, 15 ]
  max_depth: [ 2, 4, 6, 7 ]
  eta: [ 0.3, 0.1, 0.05, 0.01 ]
  subsample: [0.7, 0.8, 0.9, 1]
catboost:
  model_name: 'CatBoost'
  n_estimators: [ 1, 2, 5, 10, 15 ]
  max_depth: [ 2, 4, 6, 7 ]
  eta: [ 0.3, 0.1, 0.05, 0.01 ]
  subsample: [0.7, 0.8, 0.9, 1]
neural_net:
  neurons_cnt: [ 32, 64, 128 ]
  batch_size: [ 32, 64, 128 ]
  learning_rate: [ 0.005, 0.025, 0.05 ]
