data_preparation:
  train_ratio: 0.7
  validation_test_ratio: 0.5
  random_state: 42
regression:
  model_name: 'Lasso'
  tuning: 1
  alpha_start_value: 0.0001
  alpha_sweep_step: 0.0001
  alpha_end_value: 0.001
  l1_ratio_start_value: 0.01  
  l1_ratio_sweep_step: 0.01
  l1_ratio_end_value: 0.1
  alpha: 0.0001
  l1_ratio: 0.09
decision_tree:
  DecisionTree:
    max_depth: [ 2, 4, 6, 7, 10, 15]
    splitter: [ 'best', 'random' ]
    min_samples_split: [ 2, 3, 4 ]
    min_samples_leaf: [ 1, 2, 3, 4 ]
  RandomForest:
    n_estimators: [1, 2, 5, 10, 15, 20, 25, 30]
    max_depth: [ 2, 4, 6, 7, 10, 15]
    min_samples_split: [ 2, 3, 4, 6, 7 ]
    min_samples_leaf: [ 1, 2, 3, 4 ]
  ExtraTree:
    n_estimators: [1, 2, 5, 10, 15, 20, 25, 30]
    max_depth: [ 2, 4, 6, 7, 10, 15 ]
    min_samples_split: [ 2, 3, 4, 10, 15 ]
    min_samples_leaf: [ 1, 2, 3, 4, 18, 48 ]
xgboost:
  n_estimators: [1, 2, 5, 10, 15, 20, 25, 30, 40, 50]
  max_depth: [2, 4, 6, 7, 10, 15]
  eta: [0.8, 0.3, 0.1, 0.05, 0.01]
  subsample: [0.6, 0.7, 0.8, 0.9, 1.0]
catboost:
  iterations: [1, 2, 5, 10, 15, 20, 25, 30]
  depth: [2, 4, 6, 7, 10, 15]
  learning_rate: [0.8, 0.3, 0.1, 0.05, 0.01]
neural_network:
  batch_size: [32, 64, 128]
  buffer_size: [32, 64, 128]
  neurons: [128, 256, 512]
  learning_rate: [0.001, 0.003, 0.005]

